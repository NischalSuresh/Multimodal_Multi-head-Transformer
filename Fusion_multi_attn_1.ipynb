{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Assuming 3 modalities  \n",
        "* All the modalities are processed in parallel \n",
        "* Drop out and final Head-Proj not added to check if output matches from both implementation"
      ],
      "metadata": {
        "id": "Xog57NJTxTGd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "t-Lr2fnFxRsr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, mask = None, bias=False):\n",
        "        super().__init__()\n",
        "        #self.weight = nn.Parameter(torch.Tensor(out_features, in_features) * mask)\n",
        "        torch.manual_seed(0)\n",
        "        self.weight = torch.ones(out_features, in_features)  #weights set to 1 to check output, random seed not suitable becuase matric size is different\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.mask = mask\n",
        "\n",
        "    def forward(self, input):\n",
        "        if self.mask is None:\n",
        "          output = input.matmul(self.weight.t())\n",
        "        else:\n",
        "          output = input.matmul((self.weight * self.mask).t()) # mask added to skip connections between different modalities, see notes\n",
        "        if self.bias is not None:\n",
        "            output += self.bias\n",
        "        return output"
      ],
      "metadata": {
        "id": "ZnwO1aczx_SF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard Multi head Attention"
      ],
      "metadata": {
        "id": "_LYtsRgkBsfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_head, num_heads, num_modes, ip_dim, dropout=0.1):       \n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_head = dim_head\n",
        "        self.ip_dim = ip_dim\n",
        "        self.embed_dim = self.num_heads * self.dim_head * num_modes\n",
        "        self.query_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim)\n",
        "        self.key_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim)\n",
        "        self.value_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None):\n",
        "        N, S, D = query.shape\n",
        "        N, T, D = value.shape\n",
        "        query = self.query_proj(query)\n",
        "        key = self.key_proj(key)\n",
        "        value = self.value_proj(value)\n",
        "        dot_product = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
        "        if attn_mask is not None:\n",
        "            additive_mask = (1 - attn_mask) * -1e9\n",
        "            dot_product += additive_mask   \n",
        "        y = torch.matmul(dot_product, value)\n",
        "        return y  \n",
        "\n",
        "class MultiHeadAttentionLayer(AttentionLayer):\n",
        "\n",
        "    def __init__(self, dim_head, num_heads, num_modes, ip_dim, dropout=0.1):     \n",
        "        super().__init__(dim_head,num_heads, num_modes, ip_dim, dropout)\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_head = dim_head\n",
        "        self.num_modes = num_modes\n",
        "        self.embed_dim = self.num_heads * self.dim_head * self.num_modes\n",
        "        self.head_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None):\n",
        "        H = self.num_heads\n",
        "        N, S, D_ = query.shape\n",
        "        N, T, D_ = value.shape\n",
        "        D = self.embed_dim\n",
        "        query = self.query_proj(query).view(N, S, H, D // H).transpose(1,2)\n",
        "        key = self.key_proj(key).view(N, T, H, D // H).transpose(1,2)\n",
        "        value = self.value_proj(value).view(N, T, H, D // H).transpose(1,2)\n",
        "        dot_product = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.embed_dim / (H* self.num_modes))\n",
        "        if attn_mask is not None:\n",
        "            additive_mask = (1 - attn_mask) * -1e9\n",
        "            dot_product += additive_mask.to(query.device)      \n",
        "        y = torch.matmul(F.softmax(dot_product, dim=-1), value)\n",
        "        output = y.transpose(1,2).reshape(N, S, D)\n",
        "        return output"
      ],
      "metadata": {
        "id": "LuwM3r6NofUD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_attn = MultiHeadAttentionLayer(dim_head = 4, num_heads = 2, num_modes = 1, ip_dim = 4) #dim_head is the embedding dim per head"
      ],
      "metadata": {
        "id": "UcJH7QcTofEl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2,3,4) # modality input one of Batch_size - 2, sequence length - 3, dim - 4\n",
        "x2 = torch.rand(2,3,4) # modality input two of Batch_size - 2, sequence length - 3, dim - 4\n",
        "x3 = torch.rand(2,3,4) # modality input three of Batch_size - 2, sequence length - 3, dim - 4\n",
        "\n",
        "out1 = multi_attn(x1, x1, x1) # generate the output from all the modalities one after the other\n",
        "out2 = multi_attn(x2, x2, x2)\n",
        "out3 = multi_attn(x3, x3, x3)\n",
        "\n",
        "out = torch.cat((out1, out2, out3), -1)"
      ],
      "metadata": {
        "id": "N80liM97Ki2J"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Multi head attention with parallel processing of modalities"
      ],
      "metadata": {
        "id": "a4LT66eiVKYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuseAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_head, num_heads, num_modes, ip_dim, dropout=0.1):       \n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_head = dim_head\n",
        "        self.ip_dim = ip_dim\n",
        "        a = num_heads * dim_head\n",
        "        b = ip_dim\n",
        "        B = b * num_modes\n",
        "        out =  torch.hstack((torch.ones(a,b), torch.zeros(a,B - b)))\n",
        "        mask = out\n",
        "        for _ in range(num_modes-1):   # to generate the required mask, check notes\n",
        "          out = torch.roll(out, shifts=b, dims=-1) \n",
        "          mask = torch.vstack((mask,out))\n",
        "        self.embed_dim = self.num_heads * self.dim_head * num_modes\n",
        "        self.query_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim, mask)\n",
        "        self.key_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim, mask)\n",
        "        self.value_proj = CustomLinear(self.ip_dim * num_modes, self.embed_dim, mask)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None):\n",
        "        N, S, D = query.shape\n",
        "        N, T, D = value.shape\n",
        "        query = self.query_proj(query)\n",
        "        key = self.key_proj(key)\n",
        "        value = self.value_proj(value)\n",
        "        dot_product = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
        "        if attn_mask is not None:\n",
        "            additive_mask = (1 - attn_mask) * -1e9\n",
        "            dot_product += additive_mask   \n",
        "        y = torch.matmul(dot_product, value)\n",
        "        return y  \n",
        "\n",
        "class FuseMultiHeadAttentionLayer(FuseAttentionLayer):\n",
        "\n",
        "    def __init__(self, dim_head, num_heads, num_modes, ip_dim, dropout=0.1):     \n",
        "        super().__init__(dim_head,num_heads, num_modes, ip_dim, dropout)\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_head = dim_head\n",
        "        self.num_modes = num_modes\n",
        "        self.embed_dim = self.num_heads * self.dim_head * self.num_modes\n",
        "        self.head_proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None):\n",
        "        H = self.num_heads\n",
        "        N, S, D_ = query.shape\n",
        "        N, T, D_ = value.shape\n",
        "        D = self.embed_dim\n",
        "        M = self.num_modes\n",
        "        # query shape = Batch x seq_len x (ip_dim*Num_mode)\n",
        "        query = self.query_proj(query).view(N, S, M, D // M).transpose(-3,-2) #shape - B x N_modes x seq_len x (emb_dim/N_modes)\n",
        "        query = query.view(N, M, S, H, D // (M*H)).transpose(-3,-2) #shape - B x N_modes x N_head x seq_len x (emb_dim/(N_head * N_modes)\n",
        "        key = self.key_proj(key).view(N, S, M, D // M).transpose(-3,-2).view(N, M, S, H, D // (M*H)).transpose(-3,-2)\n",
        "        value = self.value_proj(value).view(N, S, M, D // M).transpose(-3,-2).view(N, M, S, H, D // (M*H)).transpose(-3,-2)\n",
        "        dot_product = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.embed_dim / (H* self.num_modes))\n",
        "        # print(dot_product.transpose(-1,-2).reshape(N, M, S, D//(M)).transpose(-1,-2).reshape(N, S, D))\n",
        "        # print(dot_product.shape)\n",
        "        if attn_mask is not None:\n",
        "            additive_mask = (1 - attn_mask) * -1e9\n",
        "            dot_product += additive_mask.to(query.device)      \n",
        "        y = torch.matmul(F.softmax(dot_product, dim=-1), value) #B x N_modes x N_head x seq_len x (emb_dim/(N_head * N_modes)\n",
        "        # pdb.set_trace() \n",
        "        output = y.transpose(-3,-2).reshape(N, M, S, D//(M)).transpose(-3,-2).reshape(N, S, D)\n",
        "        return output"
      ],
      "metadata": {
        "id": "oLBRmqR8VHVI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuse_multi_attn = FuseMultiHeadAttentionLayer(dim_head = 4, num_heads = 2, num_modes = 3, ip_dim = 4) #dim_head is the embedding dim per head\n",
        "x_cat = torch.cat((x1,x2,x3),-1)  # concatenate all the different modes together\n",
        "out_fuse = fuse_multi_attn(x_cat, x_cat, x_cat) # generate the output from the cancatenated input"
      ],
      "metadata": {
        "id": "FtWBKsZBBMMu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_fuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-4D0hTHD_Ya",
        "outputId": "76ab13c2-460c-4fe3-9145-c88a4cc182d4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.6792, 2.6792, 2.6792, 2.6792, 2.6792, 2.6792, 2.6792, 2.6792,\n",
              "          2.3100, 2.3100, 2.3100, 2.3100, 2.3100, 2.3100, 2.3100, 2.3100,\n",
              "          2.5008, 2.5008, 2.5008, 2.5008, 2.5008, 2.5008, 2.5008, 2.5008],\n",
              "         [2.6011, 2.6011, 2.6011, 2.6011, 2.6011, 2.6011, 2.6011, 2.6011,\n",
              "          2.3598, 2.3598, 2.3598, 2.3598, 2.3598, 2.3598, 2.3598, 2.3598,\n",
              "          2.4687, 2.4687, 2.4687, 2.4687, 2.4687, 2.4687, 2.4687, 2.4687],\n",
              "         [2.6354, 2.6354, 2.6354, 2.6354, 2.6354, 2.6354, 2.6354, 2.6354,\n",
              "          2.2682, 2.2682, 2.2682, 2.2682, 2.2682, 2.2682, 2.2682, 2.2682,\n",
              "          2.4149, 2.4149, 2.4149, 2.4149, 2.4149, 2.4149, 2.4149, 2.4149]],\n",
              "\n",
              "        [[2.7431, 2.7431, 2.7431, 2.7431, 2.7431, 2.7431, 2.7431, 2.7431,\n",
              "          2.0634, 2.0634, 2.0634, 2.0634, 2.0634, 2.0634, 2.0634, 2.0634,\n",
              "          2.4275, 2.4275, 2.4275, 2.4275, 2.4275, 2.4275, 2.4275, 2.4275],\n",
              "         [2.6861, 2.6861, 2.6861, 2.6861, 2.6861, 2.6861, 2.6861, 2.6861,\n",
              "          2.0877, 2.0877, 2.0877, 2.0877, 2.0877, 2.0877, 2.0877, 2.0877,\n",
              "          2.4886, 2.4886, 2.4886, 2.4886, 2.4886, 2.4886, 2.4886, 2.4886],\n",
              "         [2.7066, 2.7066, 2.7066, 2.7066, 2.7066, 2.7066, 2.7066, 2.7066,\n",
              "          2.0270, 2.0270, 2.0270, 2.0270, 2.0270, 2.0270, 2.0270, 2.0270,\n",
              "          2.4566, 2.4566, 2.4566, 2.4566, 2.4566, 2.4566, 2.4566, 2.4566]]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(out_fuse, out) # check if the output from both the methods are the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXK0RNyIH9Ox",
        "outputId": "80335d62-2558-4889-c81d-86fd1dd4273a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Comparasion"
      ],
      "metadata": {
        "id": "uHCoOL0_8TI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "4Qpbqlsb8o69"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "start_time1 = time.time()\n",
        "for _ in range(10000):\n",
        "  x1 = torch.rand(2,3,4) \n",
        "  x2 = torch.rand(2,3,4) \n",
        "  x3 = torch.rand(2,3,4) \n",
        "\n",
        "  out1 = multi_attn(x1, x1, x1)\n",
        "  out2 = multi_attn(x2, x2, x2)\n",
        "  out3 = multi_attn(x3, x3, x3)\n",
        "\n",
        "  out = torch.cat((out1, out2, out3), -1)\n",
        "end_time1 = time.time()\n",
        "time_1 = end_time1 - start_time1"
      ],
      "metadata": {
        "id": "Sc9rxHAL8S6e"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "start_time2 = time.time()\n",
        "for _ in range(10000):\n",
        "  x1 = torch.rand(2,3,4) \n",
        "  x2 = torch.rand(2,3,4) \n",
        "  x3 = torch.rand(2,3,4) \n",
        "\n",
        "  x_cat = torch.cat((x1,x2,x3),-1)\n",
        "  out_fuse = fuse_multi_attn(x_cat, x_cat, x_cat)\n",
        "end_time2 = time.time()\n",
        "time_2 = end_time2 - start_time2"
      ],
      "metadata": {
        "id": "sqemBB0l1A7h"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_std_multihead = round(time_1,2)\n",
        "time_my_multihead = round(time_2,2)"
      ],
      "metadata": {
        "id": "5wjpf0Y9IlYA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_std_multihead # time for standard implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JRTT_Mu9rsR",
        "outputId": "a0a511bb-b52d-4731-8205-8900699661ee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.6"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_my_multihead # time for modified implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ki_k299yWA",
        "outputId": "424cedb2-8f8e-471e-88de-672007f6729e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.61"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_std_multihead/time_my_multihead # should be around 3 times faster since there are 3 modalities. The time complexity scales linearly with modes in standard implementation but it is constant is the modified implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8F5ltFx90IZ",
        "outputId": "05c7863f-cb10-4936-bb9a-96b7bb089b08"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1455938697318007"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}